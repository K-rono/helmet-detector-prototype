{"cells":[{"cell_type":"markdown","metadata":{"id":"Qf-uuks2ka3c"},"source":["## Preprocess and Train Model"]},{"cell_type":"markdown","metadata":{"id":"giDQdGFNka3d"},"source":["### Install Required Packages"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"aS0QYBO1ka3e","executionInfo":{"status":"ok","timestamp":1756887427880,"user_tz":-480,"elapsed":359633,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"}},"outputId":"4e990672-9b5b-489e-f49f-197ec58c3521"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n","Collecting torchvision==0.22.1+cu118\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n","Collecting numpy (from torchvision==0.22.1+cu118)\n","  Downloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m300.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch==2.7.1 (from torchvision==0.22.1+cu118)\n","  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (28 kB)\n","Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.22.1+cu118)\n","  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n","Collecting filelock (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n","Collecting typing-extensions>=4.10.0 (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n","Collecting setuptools (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n","Collecting sympy>=1.13.3 (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n","Collecting networkx (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n","Collecting jinja2 (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n","Collecting fsspec (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n","Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.3.0.86 (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-nccl-cu11==2.21.5 (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==3.3.1 (from torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading https://download.pytorch.org/whl/triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n","Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2->torch==2.7.1->torchvision==0.22.1+cu118)\n","  Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n","Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl (6.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl (905.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m905.2/905.2 MB\u001b[0m \u001b[31m418.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl (417.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (23.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (875 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl (58.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl (128.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m887.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl (204.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filelock-3.19.1-py3-none-any.whl (15 kB)\n","Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading networkx-3.5-py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n","Installing collected packages: mpmath, typing-extensions, sympy, setuptools, pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jinja2, torch, torchvision\n","  Attempting uninstall: mpmath\n","    Found existing installation: mpmath 1.3.0\n","    Uninstalling mpmath-1.3.0:\n","      Successfully uninstalled mpmath-1.3.0\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.15.0\n","    Uninstalling typing_extensions-4.15.0:\n","      Successfully uninstalled typing_extensions-4.15.0\n","  Attempting uninstall: sympy\n","    Found existing installation: sympy 1.13.3\n","    Uninstalling sympy-1.13.3:\n","      Successfully uninstalled sympy-1.13.3\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 75.2.0\n","    Uninstalling setuptools-75.2.0:\n","      Successfully uninstalled setuptools-75.2.0\n","  Attempting uninstall: pillow\n","    Found existing installation: pillow 11.3.0\n","    Uninstalling pillow-11.3.0:\n","      Successfully uninstalled pillow-11.3.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.5\n","    Uninstalling networkx-3.5:\n","      Successfully uninstalled networkx-3.5\n","  Attempting uninstall: MarkupSafe\n","    Found existing installation: MarkupSafe 3.0.2\n","    Uninstalling MarkupSafe-3.0.2:\n","      Successfully uninstalled MarkupSafe-3.0.2\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.0\n","    Uninstalling fsspec-2025.3.0:\n","      Successfully uninstalled fsspec-2025.3.0\n","  Attempting uninstall: filelock\n","    Found existing installation: filelock 3.19.1\n","    Uninstalling filelock-3.19.1:\n","      Successfully uninstalled filelock-3.19.1\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.4.0\n","    Uninstalling triton-3.4.0:\n","      Successfully uninstalled triton-3.4.0\n","  Attempting uninstall: jinja2\n","    Found existing installation: Jinja2 3.1.6\n","    Uninstalling Jinja2-3.1.6:\n","      Successfully uninstalled Jinja2-3.1.6\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.8.0+cu126\n","    Uninstalling torch-2.8.0+cu126:\n","      Successfully uninstalled torch-2.8.0+cu126\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.23.0+cu126\n","    Uninstalling torchvision-0.23.0+cu126:\n","      Successfully uninstalled torchvision-0.23.0+cu126\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n","datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\n","torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.7.1+cu118 which is incompatible.\n","cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.2 which is incompatible.\n","tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.2 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed MarkupSafe-3.0.2 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-2.3.2 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 pillow-11.3.0 setuptools-80.9.0 sympy-1.14.0 torch-2.7.1+cu118 torchvision-0.22.1+cu118 triton-3.3.1 typing-extensions-4.15.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL","_distutils_hack","filelock","mpmath","numpy","sympy","torch","torchgen","torchvision","triton"]},"id":"f508fb219add41c9a9fbe3829aa4fb39"}},"metadata":{}}],"source":["%pip install torchvision==0.22.1+cu118 --extra-index-url https://download.pytorch.org/whl/cu118 --force-reinstall"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"kvKKnubeka3e","outputId":"9b37ba05-f5af-442a-96ea-e15023dfef4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting kagglehub[pandas-datasets]\n","  Downloading kagglehub-0.3.13-py3-none-any.whl.metadata (38 kB)\n","Requirement already satisfied: packaging in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from kagglehub[pandas-datasets]) (24.2)\n","Requirement already satisfied: pyyaml in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from kagglehub[pandas-datasets]) (6.0.2)\n","Requirement already satisfied: requests in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from kagglehub[pandas-datasets]) (2.32.3)\n","Requirement already satisfied: tqdm in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from kagglehub[pandas-datasets]) (4.67.1)\n","Requirement already satisfied: pandas in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from kagglehub[pandas-datasets]) (2.2.3)\n","Requirement already satisfied: numpy>=1.26.0 in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2.1.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n","Requirement already satisfied: six>=1.5 in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->kagglehub[pandas-datasets]) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (2025.7.14)\n","Requirement already satisfied: colorama in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from tqdm->kagglehub[pandas-datasets]) (0.4.6)\n","Downloading kagglehub-0.3.13-py3-none-any.whl (68 kB)\n","Installing collected packages: kagglehub\n","Successfully installed kagglehub-0.3.13\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install kagglehub[pandas-datasets]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"u1wPyTkOka3f","outputId":"34cb3b36-6dfa-49d3-cc1b-8c6ea9355f7c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting albumentations\n","  Downloading albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n","Requirement already satisfied: numpy>=1.24.4 in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from albumentations) (2.1.3)\n","Requirement already satisfied: scipy>=1.10.0 in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from albumentations) (1.15.3)\n","Requirement already satisfied: PyYAML in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from albumentations) (6.0.2)\n","Requirement already satisfied: pydantic>=2.9.2 in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from albumentations) (2.10.3)\n","Collecting albucore==0.0.24 (from albumentations)\n","  Downloading albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n","Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n","  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (20 kB)\n","Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations)\n","  Downloading stringzilla-3.12.6-cp313-cp313-win_amd64.whl.metadata (81 kB)\n","Collecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations)\n","  Downloading simsimd-6.5.1-cp313-cp313-win_amd64.whl.metadata (72 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (2.27.1)\n","Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\shircheng\\anaconda3\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (4.15.0)\n","Downloading albumentations-2.0.8-py3-none-any.whl (369 kB)\n","Downloading albucore-0.0.24-py3-none-any.whl (15 kB)\n","Downloading opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl (38.9 MB)\n","   ---------------------------------------- 0.0/38.9 MB ? eta -:--:--\n","    --------------------------------------- 0.8/38.9 MB 4.7 MB/s eta 0:00:09\n","   - -------------------------------------- 1.0/38.9 MB 4.9 MB/s eta 0:00:08\n","   -- ------------------------------------- 2.1/38.9 MB 3.6 MB/s eta 0:00:11\n","   --- ------------------------------------ 3.4/38.9 MB 4.3 MB/s eta 0:00:09\n","   ------ --------------------------------- 6.0/38.9 MB 6.1 MB/s eta 0:00:06\n","   ------- -------------------------------- 7.1/38.9 MB 5.9 MB/s eta 0:00:06\n","   ------------ --------------------------- 12.1/38.9 MB 8.7 MB/s eta 0:00:04\n","   ---------------- ----------------------- 16.5/38.9 MB 10.3 MB/s eta 0:00:03\n","   --------------------- ------------------ 21.2/38.9 MB 11.7 MB/s eta 0:00:02\n","   ---------------------------- ----------- 28.0/38.9 MB 13.9 MB/s eta 0:00:01\n","   ------------------------------------- -- 36.2/38.9 MB 16.2 MB/s eta 0:00:01\n","   ---------------------------------------- 38.9/38.9 MB 16.5 MB/s eta 0:00:00\n","Downloading simsimd-6.5.1-cp313-cp313-win_amd64.whl (94 kB)\n","Downloading stringzilla-3.12.6-cp313-cp313-win_amd64.whl (79 kB)\n","Installing collected packages: stringzilla, simsimd, opencv-python-headless, albucore, albumentations\n","\n","   ---------------- ----------------------- 2/5 [opencv-python-headless]\n","   ---------------- ----------------------- 2/5 [opencv-python-headless]\n","   ---------------- ----------------------- 2/5 [opencv-python-headless]\n","   -------------------------------- ------- 4/5 [albumentations]\n","   -------------------------------- ------- 4/5 [albumentations]\n","   ---------------------------------------- 5/5 [albumentations]\n","\n","Successfully installed albucore-0.0.24 albumentations-2.0.8 opencv-python-headless-4.12.0.88 simsimd-6.5.1 stringzilla-3.12.6\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["# Install torchmetrics for image augmentation\n","%pip install albumentations"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":9405,"status":"ok","timestamp":1756888006335,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"},"user_tz":-480},"id":"t-m7wsX5vPOP","outputId":"2a56cd66-52f5-47a0-de9a-fd0e146be3ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchmetrics\n","  Downloading torchmetrics-1.8.1-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.19.1)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n","Downloading torchmetrics-1.8.1-py3-none-any.whl (982 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.0/983.0 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n","Installing collected packages: lightning-utilities, torchmetrics\n","Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.1\n"]}],"source":["# Install torchmetrics for evaluation metrics\n","%pip install torchmetrics"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31586,"status":"ok","timestamp":1756887727888,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"},"user_tz":-480},"id":"DrH_To_H_aI6","outputId":"fb1fcfff-dfb1-446f-9af4-3be0a331cf98"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rMcRRWQmka3g","executionInfo":{"status":"ok","timestamp":1756888417767,"user_tz":-480,"elapsed":4,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"}},"outputId":"7319a2d4-60cf-4f83-f520-8a2b0cfddac3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Torch: 2.8.0+cu126\n","Torchvision: 0.23.0+cu126\n","CUDA available: True\n","CUDA version: 12.6\n"]}],"source":["import torch, torchvision\n","print(\"Torch:\", torch.__version__)\n","print(\"Torchvision:\", torchvision.__version__)\n","print(\"CUDA available:\", torch.cuda.is_available())\n","print(\"CUDA version:\", torch.version.cuda)\n"]},{"cell_type":"markdown","metadata":{"id":"seSSTRgtka3h"},"source":["### Prepare Data"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nXYjGcwFka3h","executionInfo":{"status":"ok","timestamp":1756887749041,"user_tz":-480,"elapsed":3245,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"}},"outputId":"dc53d6c5-66f0-4f20-f8d3-67e024f69788"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset downloaded to: /kaggle/input/helmet-dataset-by-osf-lite\n"]}],"source":["import kagglehub\n","\n","# Set the handle for the dataset\n","dataset_handle = \"kronomy/helmet-dataset-by-osf-lite\"\n","\n","# Download the latest version of the dataset\n","# This will download the entire dataset to a local path\n","try:\n","  path = kagglehub.dataset_download(dataset_handle)\n","  print(f\"Dataset downloaded to: {path}\")\n","except Exception as e:\n","  print(f\"Error downloading dataset: {e}\")\n","  path = None # Set path to None if download fails for subsequent checks"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xbSIDYw8ka3h","executionInfo":{"status":"ok","timestamp":1756887750802,"user_tz":-480,"elapsed":5,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"}},"outputId":"9296357a-0d52-444d-a33f-4b2b937aae26"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset path set to: /kaggle/input/helmet-dataset-by-osf-lite/helmet-dataset\n"]}],"source":["# Path to dataset\n","dataset_path = path + '/helmet-dataset' # Use the path from kagglehub.dataset_download\n","\n","print(f\"Dataset path set to: {dataset_path}\")"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"DtUiPVqzka3i","executionInfo":{"status":"ok","timestamp":1756887751627,"user_tz":-480,"elapsed":16,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"}}},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","import json\n","from PIL import Image\n","import os\n","import torch.optim as optim\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","import numpy as np\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","\n","# --- Dataset ---\n","\n","class CustomFasterRCNNDataset(Dataset):\n","    def __init__(self, image_dir, annotation_file, transform=None):\n","        self.image_dir = image_dir\n","        self.annotation_file = annotation_file\n","        self.transform = transform\n","        with open(annotation_file, 'r') as f:\n","            self.annotations = json.load(f)\n","\n","        self.class_to_label = {\n","            'DHelmet': 1,\n","            'DNoHelmet': 2,\n","            'DHelmetP1Helmet': 3,\n","            'DNoHelmetP1NoHelmet': 4\n","        }\n","        self.label_to_class = {v: k for k, v in self.class_to_label.items()}\n","        self.label_to_class[0] = 'background'\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, idx):\n","        image_file_name = list(self.annotations.keys())[idx]\n","        img_path = os.path.join(self.image_dir, image_file_name)\n","\n","        img = Image.open(img_path).convert(\"RGB\")\n","        # Convert PIL Image to NumPy array (required by Albumentations)\n","        img_np = np.array(img)\n","\n","        image_annotations = self.annotations[image_file_name]\n","\n","        boxes, labels = [], []\n","        for annotation in image_annotations:\n","            x_min, y_min, x_max, y_max = annotation['bbox']\n","\n","            # Filter invalid boxes (zero or negative area)\n","            if x_max > x_min and y_max > y_min:\n","                boxes.append([x_min, y_min, x_max, y_max])\n","                label = annotation['label']\n","                if isinstance(label, str):\n","                    labels.append(self.class_to_label[label])\n","                else:\n","                    labels.append(label)\n","            else:\n","                print(f\"[Warning] Invalid box in {image_file_name}: {annotation['bbox']}\")\n","\n","\n","        # Apply Albumentations transform to both image and target (boxes and labels)\n","        if self.transform is not None and len(boxes) > 0:\n","            # Albumentations transform takes image and a dictionary of targets\n","            # Ensure boxes is a list of lists or numpy array\n","            transformed = self.transform(image=img_np, bboxes=boxes, labels=labels)\n","            img_np = transformed['image']\n","            boxes = transformed['bboxes']\n","            labels = transformed['labels']\n","\n","        # Convert augmented NumPy image back to PyTorch tensor\n","        img_tensor = torch.from_numpy(img_np).permute(2, 0, 1).float() / 255.0 # HWC to CHW, scale to [0, 1]\n","\n","        # Convert augmented boxes and labels back to PyTorch tensors\n","        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n","        labels = torch.as_tensor(labels, dtype=torch.int64)\n","\n","        # Handle empty boxes case\n","        if len(boxes) == 0:\n","            # Create empty tensors with proper shape for empty case\n","            boxes = torch.zeros((0, 4), dtype=torch.float32)\n","            labels = torch.zeros((0,), dtype=torch.int64)\n","            area = torch.zeros((0,), dtype=torch.float32)\n","            iscrowd = torch.zeros((0,), dtype=torch.int64)\n","        else:\n","            # Calculate area for non-empty boxes\n","            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n","            iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n","\n","        target = {\n","            \"boxes\": boxes,\n","            \"labels\": labels,\n","            \"image_id\": torch.tensor([idx]),\n","            \"area\": area,\n","            \"iscrowd\": iscrowd\n","        }\n","\n","        return img_tensor, target"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"svOyPKPQka3i","executionInfo":{"status":"ok","timestamp":1756887752530,"user_tz":-480,"elapsed":32,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"}}},"outputs":[],"source":["import albumentations as A\n","import cv2\n","# Define Albumentations transform\n","# This is a placeholder and will be further refined in the next subtask\n","def get_albumentations_transform(train):\n","    transform_list = []\n","    # Define bbox_params inside the function\n","    bbox_params = A.BboxParams(format='pascal_voc', label_fields=['labels'], min_area=1, min_visibility=0.1)\n","\n","    if train:\n","        transform_list.extend([\n","            # Geometric transformations with bounding box support\n","            A.HorizontalFlip(p=0.5),\n","            A.VerticalFlip(p=0.2),\n","            A.Rotate(limit=15, p=0.5, border_mode=cv2.BORDER_CONSTANT), # Requires OpenCV\n","\n","            # Photometric transformations\n","            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5), # Does not affect bounding boxes\n","            A.RandomBrightnessContrast(p=0.2),\n","        ])\n","\n","    return A.Compose(transform_list, bbox_params=bbox_params if train else None)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bYclTqUYka3i","executionInfo":{"status":"ok","timestamp":1756887761238,"user_tz":-480,"elapsed":8065,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"}},"outputId":"c42a22b9-04cf-4a72-cc74-99240baaf4ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training images: 973\n","Number of validation images: 136\n","Number of test images: 275\n"]}],"source":["# --- Prepare Data ---\n","image_location = dataset_path\n","fasterrcnn_train_json = \"/content/drive/MyDrive/DegreeY3S1/BMDS2133_ImageProcessing/Assignment/dataset/preprocessed_data/fasterrcnn_annotations/fasterrcnn_train.json\"\n","fasterrcnn_val_json = \"/content/drive/MyDrive/DegreeY3S1/BMDS2133_ImageProcessing/Assignment/dataset/preprocessed_data/fasterrcnn_annotations/fasterrcnn_val.json\"\n","fasterrcnn_test_json = \"/content/drive/MyDrive/DegreeY3S1/BMDS2133_ImageProcessing/Assignment/dataset/preprocessed_data/fasterrcnn_annotations/fasterrcnn_test.json\"\n","\n","train_dataset = CustomFasterRCNNDataset(image_location, fasterrcnn_train_json)\n","val_dataset   = CustomFasterRCNNDataset(image_location, fasterrcnn_val_json)\n","test_dataset   = CustomFasterRCNNDataset(image_location, fasterrcnn_test_json)\n","\n","train_dataset.transform = get_albumentations_transform(train=True)\n","val_dataset.transform = get_albumentations_transform(train=False)\n","test_dataset.transform = get_albumentations_transform(train=False)\n","\n","print(f\"Number of training images: {len(train_dataset)}\")\n","print(f\"Number of validation images: {len(val_dataset)}\")\n","print(f\"Number of test images: {len(test_dataset)}\")\n","\n","def collate_fn(batch):\n","    return tuple(zip(*batch))\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n","val_dataloader   = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n","test_dataloader   = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":806,"output_embedded_package_id":"1-rGFnMlRgd2M0OueStW0-ybSJzjISuA2"},"id":"fXfXds-ika3j","executionInfo":{"status":"ok","timestamp":1756889495705,"user_tz":-480,"elapsed":1671,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"}},"outputId":"c7e90dc0-cce7-46b8-9d70-c5a47fef76ae"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import cv2\n","import matplotlib.pyplot as plt\n","\n","# Get one batch\n","images, targets = next(iter(train_dataloader))\n","\n","# loop through one batch and draw bounding boxes and labels\n","for i in range(len(images)):\n","    # CxHxW --> HxWxC\n","    image = images[i].permute(1, 2, 0).numpy()\n","    # Rescale\n","    image = (image * 255).astype(np.uint8)\n","    # Convert RGB to BGR\n","    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","\n","    # get bounding box coordinates and labels\n","    boxes = targets[i]['boxes']\n","    labels = targets[i]['labels']\n","\n","    bbox_info = []  # store text info for the title\n","    for box, label in zip(boxes, labels):\n","        x1, y1, x2, y2 = map(int, box.tolist())\n","\n","        # choose color based on label\n","        if label.item() in [2, 4]:\n","            color = (0, 0, 255)   # Red (BGR)\n","        else:\n","            color = (0, 255, 0)   # Green (BGR)\n","\n","        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n","        cv2.putText(image, f\"Class {label.item()}\", (x1, y1 - 10),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n","        bbox_info.append(f\"Class {label.item()} Box: ({x1},{y1},{x2},{y2})\")\n","\n","    # get relative path from annotations\n","    image_id = targets[i]['image_id'].item()\n","    relative_path = list(train_dataset.annotations.keys())[image_id]\n","\n","    # build full path (folder + relative path)\n","    full_path = os.path.join(image_location, relative_path)\n","\n","    # Show image with bboxes using matplotlib\n","    plt.figure(figsize=(16, 12))\n","    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","    plt.axis(\"off\")\n","    plt.title(f\"Path: {full_path}\\n\" + \"\\n\".join(bbox_info))\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"O6SZs6WKka3j"},"source":["### Setup and Model Training\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sfAgzPwjka3j","executionInfo":{"status":"ok","timestamp":1756887812357,"user_tz":-480,"elapsed":33,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"}},"outputId":"a22ef2e0-bdf2-454a-8ff9-c2b5c5737307"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tesla T4\n","Using device: cuda\n"]}],"source":["print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU only\")\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DxRGS1WLka3j","executionInfo":{"status":"ok","timestamp":1756887815954,"user_tz":-480,"elapsed":1858,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"}},"outputId":"430c15e9-86dd-4058-a29f-ef0e04cd8cd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 160M/160M [00:00<00:00, 189MB/s]\n"]}],"source":["from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights\n","\n","# --- Model Setup ---\n","\n","num_classes = 5  # background + 4\n","model = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n","\n","# replace classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","model.to(device)\n","\n","# Adjust training parameters\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n","\n","# https://visionbrick.com/pipeline-for-training-custom-faster-rcnn-object-detection-models-with-pytorch/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pxoW8HAjka3j"},"outputs":[],"source":["def compute_iou(box1, box2):\n","    \"\"\"Compute IoU between two boxes (x1, y1, x2, y2).\"\"\"\n","    # Intersection box\n","    x1 = max(box1[0], box2[0])\n","    y1 = max(box1[1], box2[1])\n","    x2 = min(box1[2], box2[2])\n","    y2 = min(box1[3], box2[3])\n","\n","    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n","\n","    # Areas of each box\n","    box1_area = max(0, (box1[2] - box1[0])) * max(0, (box1[3] - box1[1]))\n","    box2_area = max(0, (box2[2] - box2[0])) * max(0, (box2[3] - box2[1]))\n","\n","    # Union\n","    union_area = box1_area + box2_area - inter_area\n","\n","    return inter_area / union_area if union_area > 0 else 0\n","\n","\n","def precision_recall_for_batch(outputs, targets, iou_threshold=0.5, conf_threshold=0.5):\n","    \"\"\"Compute precision & recall for one batch.\"\"\"\n","    total_tp, total_fp, total_fn = 0, 0, 0\n","\n","    for output, target in zip(outputs, targets):\n","        gt_boxes = target[\"boxes\"].cpu().numpy()\n","        gt_labels = target[\"labels\"].cpu().numpy()\n","        pred_boxes = output[\"boxes\"].cpu().numpy()\n","        pred_labels = output[\"labels\"].cpu().numpy()\n","        pred_scores = output[\"scores\"].cpu().numpy()\n","\n","        # filter by confidence\n","        keep = pred_scores >= conf_threshold\n","        pred_boxes, pred_labels = pred_boxes[keep], pred_labels[keep]\n","\n","        matched_gt = set()\n","        for pb, pl in zip(pred_boxes, pred_labels):\n","            match_found = False\n","            for j, (gb, gl) in enumerate(zip(gt_boxes, gt_labels)):\n","                if j in matched_gt:\n","                    continue\n","                if pl == gl and compute_iou(pb, gb) >= iou_threshold:\n","                    total_tp += 1\n","                    matched_gt.add(j)\n","                    match_found = True\n","                    break\n","            if not match_found:\n","                total_fp += 1\n","\n","        total_fn += len(gt_boxes) - len(matched_gt)\n","\n","    precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n","    recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n","    return precision, recall\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tXJVxx0tka3k"},"outputs":[],"source":["from torchmetrics.detection import MeanAveragePrecision\n","\n","def evaluate_model(model, val_dataloader, device, class_names=None):\n","    model.eval()\n","    metric = MeanAveragePrecision(class_metrics=True)\n","\n","    with torch.no_grad():\n","        for images, targets in val_dataloader:\n","            images = [img.to(device) for img in images]\n","            outputs = model(images)\n","\n","            # Move outputs & targets back to CPU for metric calculation\n","            outputs = [{k: v.cpu() for k, v in t.items()} for t in outputs]\n","            targets = [{k: v.cpu() for k, v in t.items()} for t in targets]\n","\n","            metric.update(outputs, targets)\n","\n","    results = metric.compute()\n","\n","    # Print per-class metrics\n","    if 'map_per_class' in results and results['map_per_class'] is not None:\n","        print(\"\\nPer-Class mAP:\")\n","        map_per_class = results['map_per_class']\n","\n","        # If it’s a single tensor (0-d), just print it\n","        if map_per_class.ndim == 0:\n","            label = class_names[0] if class_names else \"Class 0\"\n","            print(f\"  {label}: {map_per_class.item():.3f}\")\n","        else:\n","            for i, ap in enumerate(map_per_class):\n","                label = class_names[i] if class_names else f\"Class {i}\"\n","                print(f\"  {label}: {ap:.3f}\")\n","\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p2OeaNuFka3k","outputId":"a92f0b4c-b804-4b67-e791-baf49e8f3e9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Step [10/487], Loss: 1.1195, Precision=0.000, Recall=0.000\n","Epoch [1/5], Step [20/487], Loss: 0.8549, Precision=0.000, Recall=0.000\n","Epoch [1/5], Step [30/487], Loss: 0.7807, Precision=0.000, Recall=0.000\n","Epoch [1/5], Step [40/487], Loss: 0.7020, Precision=0.000, Recall=0.000\n","Epoch [1/5], Step [50/487], Loss: 0.6634, Precision=0.500, Recall=0.667\n","Epoch [1/5], Step [60/487], Loss: 0.6358, Precision=0.000, Recall=0.000\n","Epoch [1/5], Step [70/487], Loss: 0.5941, Precision=0.286, Recall=0.500\n","Epoch [1/5], Step [80/487], Loss: 0.5788, Precision=0.750, Recall=1.000\n","Epoch [1/5], Step [90/487], Loss: 0.5586, Precision=1.000, Recall=0.667\n","Epoch [1/5], Step [100/487], Loss: 0.5487, Precision=0.571, Recall=0.500\n","Epoch [1/5], Step [110/487], Loss: 0.5388, Precision=0.250, Recall=0.167\n","Epoch [1/5], Step [120/487], Loss: 0.5240, Precision=1.000, Recall=0.500\n","Epoch [1/5], Step [130/487], Loss: 0.5137, Precision=0.200, Recall=0.500\n","Epoch [1/5], Step [140/487], Loss: 0.5050, Precision=0.538, Recall=0.583\n","Epoch [1/5], Step [150/487], Loss: 0.4986, Precision=0.000, Recall=0.000\n","Epoch [1/5], Step [160/487], Loss: 0.4903, Precision=0.500, Recall=0.250\n","Epoch [1/5], Step [170/487], Loss: 0.4854, Precision=0.500, Recall=0.500\n","Epoch [1/5], Step [180/487], Loss: 0.4783, Precision=0.000, Recall=0.000\n","Epoch [1/5], Step [190/487], Loss: 0.4737, Precision=0.250, Recall=0.167\n","Epoch [1/5], Step [200/487], Loss: 0.4737, Precision=0.000, Recall=0.000\n","Epoch [1/5], Step [210/487], Loss: 0.4698, Precision=0.000, Recall=0.000\n","Epoch [1/5], Step [220/487], Loss: 0.4680, Precision=0.250, Recall=0.333\n","Epoch [1/5], Step [230/487], Loss: 0.4636, Precision=0.250, Recall=0.167\n","Epoch [1/5], Step [240/487], Loss: 0.4599, Precision=0.800, Recall=0.364\n","Epoch [1/5], Step [250/487], Loss: 0.4533, Precision=0.000, Recall=0.000\n","Epoch [1/5], Step [260/487], Loss: 0.4491, Precision=0.000, Recall=0.000\n","Epoch [1/5], Step [270/487], Loss: 0.4475, Precision=0.556, Recall=0.833\n","Epoch [1/5], Step [280/487], Loss: 0.4489, Precision=0.800, Recall=0.667\n","Epoch [1/5], Step [290/487], Loss: 0.4458, Precision=0.200, Recall=0.500\n","Epoch [1/5], Step [300/487], Loss: 0.4438, Precision=0.286, Recall=0.333\n","Epoch [1/5], Step [310/487], Loss: 0.4399, Precision=0.500, Recall=0.143\n","Epoch [1/5], Step [320/487], Loss: 0.4397, Precision=0.333, Recall=0.333\n","Epoch [1/5], Step [330/487], Loss: 0.4358, Precision=0.000, Recall=0.000\n","Epoch [1/5], Step [340/487], Loss: 0.4336, Precision=0.000, Recall=0.000\n","Epoch [1/5], Step [350/487], Loss: 0.4305, Precision=1.000, Recall=0.400\n","Epoch [1/5], Step [360/487], Loss: 0.4293, Precision=0.333, Recall=0.500\n","Epoch [1/5], Step [370/487], Loss: 0.4293, Precision=0.400, Recall=0.667\n","Epoch [1/5], Step [380/487], Loss: 0.4271, Precision=1.000, Recall=0.750\n","Epoch [1/5], Step [390/487], Loss: 0.4247, Precision=0.250, Recall=0.333\n","Epoch [1/5], Step [400/487], Loss: 0.4252, Precision=0.375, Recall=0.375\n","Epoch [1/5], Step [410/487], Loss: 0.4255, Precision=0.250, Recall=0.250\n","Epoch [1/5], Step [420/487], Loss: 0.4242, Precision=0.143, Recall=0.182\n","Epoch [1/5], Step [430/487], Loss: 0.4242, Precision=0.833, Recall=0.714\n","Epoch [1/5], Step [440/487], Loss: 0.4226, Precision=1.000, Recall=0.750\n","Epoch [1/5], Step [450/487], Loss: 0.4222, Precision=0.100, Recall=0.167\n","Epoch [1/5], Step [460/487], Loss: 0.4209, Precision=1.000, Recall=0.167\n","Epoch [1/5], Step [470/487], Loss: 0.4198, Precision=1.000, Recall=0.556\n","Epoch [1/5], Step [480/487], Loss: 0.4187, Precision=0.500, Recall=0.500\n","\n","Per-Class mAP:\n","  DHelmet: 0.410\n","  DNoHelmet: 0.219\n","  DHelmetP1Helmet: 0.216\n","  DNoHelmetP1NoHelmet: 0.047\n","Epoch [1/5] finished, Avg Loss: 0.4174, Avg Precision=0.394, Avg Recall=0.325, Validation mAP=0.223, Validation mAR=0.662\n","{'map': tensor(0.2231), 'map_50': tensor(0.3113), 'map_75': tensor(0.2802), 'map_small': tensor(-1.), 'map_medium': tensor(0.2043), 'map_large': tensor(0.2414), 'mar_1': tensor(0.3065), 'mar_10': tensor(0.6620), 'mar_100': tensor(0.6620), 'mar_small': tensor(-1.), 'mar_medium': tensor(0.5036), 'mar_large': tensor(0.6946), 'map_per_class': tensor([0.4100, 0.2189, 0.2164, 0.0472]), 'mar_100_per_class': tensor([0.7332, 0.6750, 0.6926, 0.5471]), 'classes': tensor([1, 2, 3, 4], dtype=torch.int32)}\n","Epoch [2/5], Step [10/487], Loss: 0.3472, Precision=0.333, Recall=0.200\n","Epoch [2/5], Step [20/487], Loss: 0.3459, Precision=0.667, Recall=0.667\n","Epoch [2/5], Step [30/487], Loss: 0.3413, Precision=0.000, Recall=0.000\n","Epoch [2/5], Step [40/487], Loss: 0.3318, Precision=0.375, Recall=0.500\n","Epoch [2/5], Step [50/487], Loss: 0.3380, Precision=0.500, Recall=0.600\n","Epoch [2/5], Step [60/487], Loss: 0.3436, Precision=0.286, Recall=0.333\n","Epoch [2/5], Step [70/487], Loss: 0.3621, Precision=0.571, Recall=0.444\n","Epoch [2/5], Step [80/487], Loss: 0.3681, Precision=0.375, Recall=0.375\n","Epoch [2/5], Step [90/487], Loss: 0.3559, Precision=0.667, Recall=0.800\n","Epoch [2/5], Step [100/487], Loss: 0.3557, Precision=0.429, Recall=0.429\n","Epoch [2/5], Step [110/487], Loss: 0.3514, Precision=0.600, Recall=0.600\n","Epoch [2/5], Step [120/487], Loss: 0.3516, Precision=0.455, Recall=0.625\n","Epoch [2/5], Step [130/487], Loss: 0.3537, Precision=0.500, Recall=0.400\n","Epoch [2/5], Step [140/487], Loss: 0.3560, Precision=0.200, Recall=0.250\n","Epoch [2/5], Step [150/487], Loss: 0.3517, Precision=0.200, Recall=0.167\n","Epoch [2/5], Step [160/487], Loss: 0.3503, Precision=1.000, Recall=1.000\n","Epoch [2/5], Step [170/487], Loss: 0.3478, Precision=0.667, Recall=0.500\n","Epoch [2/5], Step [180/487], Loss: 0.3434, Precision=1.000, Recall=0.500\n","Epoch [2/5], Step [190/487], Loss: 0.3422, Precision=0.600, Recall=0.750\n","Epoch [2/5], Step [200/487], Loss: 0.3433, Precision=1.000, Recall=0.333\n","Epoch [2/5], Step [210/487], Loss: 0.3435, Precision=0.111, Recall=0.091\n","Epoch [2/5], Step [220/487], Loss: 0.3438, Precision=0.250, Recall=0.200\n","Epoch [2/5], Step [230/487], Loss: 0.3452, Precision=0.167, Recall=0.167\n","Epoch [2/5], Step [240/487], Loss: 0.3446, Precision=0.000, Recall=0.000\n","Epoch [2/5], Step [250/487], Loss: 0.3463, Precision=0.500, Recall=0.429\n","Epoch [2/5], Step [260/487], Loss: 0.3491, Precision=0.600, Recall=0.500\n","Epoch [2/5], Step [270/487], Loss: 0.3467, Precision=0.000, Recall=0.000\n","Epoch [2/5], Step [280/487], Loss: 0.3463, Precision=0.667, Recall=1.000\n","Epoch [2/5], Step [290/487], Loss: 0.3481, Precision=0.250, Recall=0.250\n","Epoch [2/5], Step [300/487], Loss: 0.3469, Precision=0.571, Recall=0.571\n","Epoch [2/5], Step [310/487], Loss: 0.3460, Precision=1.000, Recall=1.000\n","Epoch [2/5], Step [320/487], Loss: 0.3458, Precision=0.286, Recall=0.286\n","Epoch [2/5], Step [330/487], Loss: 0.3436, Precision=0.625, Recall=0.455\n","Epoch [2/5], Step [340/487], Loss: 0.3432, Precision=0.200, Recall=0.200\n","Epoch [2/5], Step [350/487], Loss: 0.3436, Precision=0.333, Recall=0.500\n","Epoch [2/5], Step [360/487], Loss: 0.3432, Precision=0.000, Recall=0.000\n","Epoch [2/5], Step [370/487], Loss: 0.3434, Precision=0.750, Recall=0.600\n","Epoch [2/5], Step [380/487], Loss: 0.3429, Precision=0.000, Recall=0.000\n","Epoch [2/5], Step [390/487], Loss: 0.3419, Precision=0.667, Recall=1.000\n","Epoch [2/5], Step [400/487], Loss: 0.3413, Precision=0.750, Recall=0.600\n","Epoch [2/5], Step [410/487], Loss: 0.3402, Precision=0.556, Recall=0.714\n","Epoch [2/5], Step [420/487], Loss: 0.3401, Precision=0.667, Recall=0.667\n","Epoch [2/5], Step [430/487], Loss: 0.3407, Precision=0.667, Recall=1.000\n","Epoch [2/5], Step [440/487], Loss: 0.3417, Precision=0.400, Recall=0.400\n","Epoch [2/5], Step [450/487], Loss: 0.3414, Precision=0.500, Recall=0.333\n","Epoch [2/5], Step [460/487], Loss: 0.3413, Precision=1.000, Recall=0.500\n","Epoch [2/5], Step [470/487], Loss: 0.3442, Precision=0.167, Recall=0.143\n","Epoch [2/5], Step [480/487], Loss: 0.3448, Precision=0.143, Recall=0.143\n","\n","Per-Class mAP:\n","  DHelmet: 0.499\n","  DNoHelmet: 0.309\n","  DHelmetP1Helmet: 0.240\n","  DNoHelmetP1NoHelmet: 0.137\n","Epoch [2/5] finished, Avg Loss: 0.3445, Avg Precision=0.482, Avg Recall=0.445, Validation mAP=0.296, Validation mAR=0.731\n","{'map': tensor(0.2961), 'map_50': tensor(0.3954), 'map_75': tensor(0.3701), 'map_small': tensor(-1.), 'map_medium': tensor(0.1927), 'map_large': tensor(0.3183), 'mar_1': tensor(0.3903), 'mar_10': tensor(0.7305), 'mar_100': tensor(0.7315), 'mar_small': tensor(-1.), 'mar_medium': tensor(0.5892), 'mar_large': tensor(0.7599), 'map_per_class': tensor([0.4987, 0.3088, 0.2398, 0.1370]), 'mar_100_per_class': tensor([0.7604, 0.7125, 0.6882, 0.7647]), 'classes': tensor([1, 2, 3, 4], dtype=torch.int32)}\n","Epoch [3/5], Step [10/487], Loss: 0.2994, Precision=0.333, Recall=0.286\n","Epoch [3/5], Step [20/487], Loss: 0.3061, Precision=0.500, Recall=0.571\n","Epoch [3/5], Step [30/487], Loss: 0.3009, Precision=0.500, Recall=0.667\n","Epoch [3/5], Step [40/487], Loss: 0.2949, Precision=0.250, Recall=0.286\n","Epoch [3/5], Step [50/487], Loss: 0.2992, Precision=0.333, Recall=0.250\n","Epoch [3/5], Step [60/487], Loss: 0.3045, Precision=0.500, Recall=0.364\n","Epoch [3/5], Step [70/487], Loss: 0.2945, Precision=0.625, Recall=0.625\n","Epoch [3/5], Step [80/487], Loss: 0.2904, Precision=1.000, Recall=0.200\n","Epoch [3/5], Step [90/487], Loss: 0.3009, Precision=0.692, Recall=0.643\n","Epoch [3/5], Step [100/487], Loss: 0.2996, Precision=0.667, Recall=0.667\n","Epoch [3/5], Step [110/487], Loss: 0.2993, Precision=0.538, Recall=0.500\n","Epoch [3/5], Step [120/487], Loss: 0.3043, Precision=1.000, Recall=1.000\n","Epoch [3/5], Step [130/487], Loss: 0.3022, Precision=0.750, Recall=0.750\n","Epoch [3/5], Step [140/487], Loss: 0.3017, Precision=0.833, Recall=1.000\n","Epoch [3/5], Step [150/487], Loss: 0.3056, Precision=0.429, Recall=0.500\n","Epoch [3/5], Step [160/487], Loss: 0.3041, Precision=0.200, Recall=0.333\n","Epoch [3/5], Step [170/487], Loss: 0.3044, Precision=0.625, Recall=0.625\n","Epoch [3/5], Step [180/487], Loss: 0.3079, Precision=0.833, Recall=1.000\n","Epoch [3/5], Step [190/487], Loss: 0.3046, Precision=0.750, Recall=1.000\n","Epoch [3/5], Step [200/487], Loss: 0.3018, Precision=0.400, Recall=0.500\n","Epoch [3/5], Step [210/487], Loss: 0.3027, Precision=0.200, Recall=0.222\n","Epoch [3/5], Step [220/487], Loss: 0.3027, Precision=0.333, Recall=0.400\n","Epoch [3/5], Step [230/487], Loss: 0.3046, Precision=0.833, Recall=0.500\n","Epoch [3/5], Step [240/487], Loss: 0.3065, Precision=0.583, Recall=0.636\n","Epoch [3/5], Step [250/487], Loss: 0.3060, Precision=0.167, Recall=0.333\n","Epoch [3/5], Step [260/487], Loss: 0.3065, Precision=0.000, Recall=0.000\n","Epoch [3/5], Step [270/487], Loss: 0.3107, Precision=0.500, Recall=0.222\n","Epoch [3/5], Step [280/487], Loss: 0.3102, Precision=0.667, Recall=0.571\n","Epoch [3/5], Step [290/487], Loss: 0.3110, Precision=0.400, Recall=0.400\n","Epoch [3/5], Step [300/487], Loss: 0.3118, Precision=0.400, Recall=0.400\n","Epoch [3/5], Step [310/487], Loss: 0.3100, Precision=0.600, Recall=0.500\n","Epoch [3/5], Step [320/487], Loss: 0.3100, Precision=0.625, Recall=0.417\n","Epoch [3/5], Step [330/487], Loss: 0.3092, Precision=0.667, Recall=0.667\n","Epoch [3/5], Step [340/487], Loss: 0.3084, Precision=0.400, Recall=0.333\n","Epoch [3/5], Step [350/487], Loss: 0.3077, Precision=0.000, Recall=0.000\n","Epoch [3/5], Step [360/487], Loss: 0.3086, Precision=0.500, Recall=0.600\n","Epoch [3/5], Step [370/487], Loss: 0.3076, Precision=0.556, Recall=0.714\n","Epoch [3/5], Step [380/487], Loss: 0.3083, Precision=0.333, Recall=0.429\n","Epoch [3/5], Step [390/487], Loss: 0.3068, Precision=0.000, Recall=0.000\n","Epoch [3/5], Step [400/487], Loss: 0.3071, Precision=0.375, Recall=0.600\n","Epoch [3/5], Step [410/487], Loss: 0.3071, Precision=0.500, Recall=0.500\n","Epoch [3/5], Step [420/487], Loss: 0.3066, Precision=0.800, Recall=0.800\n","Epoch [3/5], Step [430/487], Loss: 0.3081, Precision=0.200, Recall=0.250\n","Epoch [3/5], Step [440/487], Loss: 0.3095, Precision=0.857, Recall=1.000\n","Epoch [3/5], Step [450/487], Loss: 0.3094, Precision=0.714, Recall=0.833\n","Epoch [3/5], Step [460/487], Loss: 0.3099, Precision=0.364, Recall=0.571\n","Epoch [3/5], Step [470/487], Loss: 0.3112, Precision=0.667, Recall=0.714\n","Epoch [3/5], Step [480/487], Loss: 0.3109, Precision=0.667, Recall=1.000\n","\n","Per-Class mAP:\n","  DHelmet: 0.493\n","  DNoHelmet: 0.286\n","  DHelmetP1Helmet: 0.383\n","  DNoHelmetP1NoHelmet: 0.102\n","Epoch [3/5] finished, Avg Loss: 0.3118, Avg Precision=0.520, Avg Recall=0.529, Validation mAP=0.316, Validation mAR=0.682\n","{'map': tensor(0.3159), 'map_50': tensor(0.4372), 'map_75': tensor(0.4022), 'map_small': tensor(-1.), 'map_medium': tensor(0.1812), 'map_large': tensor(0.3463), 'mar_1': tensor(0.3779), 'mar_10': tensor(0.6811), 'mar_100': tensor(0.6821), 'mar_small': tensor(-1.), 'mar_medium': tensor(0.4580), 'mar_large': tensor(0.7268), 'map_per_class': tensor([0.4931, 0.2860, 0.3826, 0.1018]), 'mar_100_per_class': tensor([0.7128, 0.6729, 0.7221, 0.6206]), 'classes': tensor([1, 2, 3, 4], dtype=torch.int32)}\n","Epoch [4/5], Step [10/487], Loss: 0.2590, Precision=0.000, Recall=0.000\n","Epoch [4/5], Step [20/487], Loss: 0.2908, Precision=0.600, Recall=0.750\n","Epoch [4/5], Step [30/487], Loss: 0.2941, Precision=0.500, Recall=0.571\n","Epoch [4/5], Step [40/487], Loss: 0.3008, Precision=0.400, Recall=0.500\n","Epoch [4/5], Step [50/487], Loss: 0.3154, Precision=0.333, Recall=0.400\n","Epoch [4/5], Step [60/487], Loss: 0.3055, Precision=0.800, Recall=0.800\n","Epoch [4/5], Step [70/487], Loss: 0.2992, Precision=0.000, Recall=0.000\n","Epoch [4/5], Step [80/487], Loss: 0.2978, Precision=0.625, Recall=0.833\n","Epoch [4/5], Step [90/487], Loss: 0.2993, Precision=0.875, Recall=0.700\n","Epoch [4/5], Step [100/487], Loss: 0.2989, Precision=0.250, Recall=0.500\n","Epoch [4/5], Step [110/487], Loss: 0.2970, Precision=0.500, Recall=0.667\n","Epoch [4/5], Step [120/487], Loss: 0.2911, Precision=1.000, Recall=0.778\n","Epoch [4/5], Step [130/487], Loss: 0.2900, Precision=0.000, Recall=0.000\n","Epoch [4/5], Step [140/487], Loss: 0.2900, Precision=0.667, Recall=0.400\n","Epoch [4/5], Step [150/487], Loss: 0.2987, Precision=0.857, Recall=0.857\n","Epoch [4/5], Step [160/487], Loss: 0.3047, Precision=0.667, Recall=0.800\n","Epoch [4/5], Step [170/487], Loss: 0.3059, Precision=0.438, Recall=0.636\n","Epoch [4/5], Step [180/487], Loss: 0.3036, Precision=0.571, Recall=0.800\n","Epoch [4/5], Step [190/487], Loss: 0.3036, Precision=0.667, Recall=0.800\n","Epoch [4/5], Step [200/487], Loss: 0.3088, Precision=0.222, Recall=0.222\n","Epoch [4/5], Step [210/487], Loss: 0.3084, Precision=0.727, Recall=0.667\n","Epoch [4/5], Step [220/487], Loss: 0.3063, Precision=0.875, Recall=1.000\n","Epoch [4/5], Step [230/487], Loss: 0.3048, Precision=0.667, Recall=0.800\n","Epoch [4/5], Step [240/487], Loss: 0.3036, Precision=1.000, Recall=1.000\n","Epoch [4/5], Step [250/487], Loss: 0.3020, Precision=0.000, Recall=0.000\n","Epoch [4/5], Step [260/487], Loss: 0.3012, Precision=0.692, Recall=0.818\n","Epoch [4/5], Step [270/487], Loss: 0.3018, Precision=0.412, Recall=0.583\n","Epoch [4/5], Step [280/487], Loss: 0.3019, Precision=0.714, Recall=0.833\n","Epoch [4/5], Step [290/487], Loss: 0.3025, Precision=0.667, Recall=0.667\n","Epoch [4/5], Step [300/487], Loss: 0.3041, Precision=0.667, Recall=1.000\n","Epoch [4/5], Step [310/487], Loss: 0.3013, Precision=0.714, Recall=0.625\n","Epoch [4/5], Step [320/487], Loss: 0.2980, Precision=0.400, Recall=1.000\n","Epoch [4/5], Step [330/487], Loss: 0.2984, Precision=0.833, Recall=0.714\n","Epoch [4/5], Step [340/487], Loss: 0.2961, Precision=0.500, Recall=1.000\n","Epoch [4/5], Step [350/487], Loss: 0.2955, Precision=0.500, Recall=0.500\n","Epoch [4/5], Step [360/487], Loss: 0.2954, Precision=0.500, Recall=0.400\n","Epoch [4/5], Step [370/487], Loss: 0.2946, Precision=1.000, Recall=1.000\n","Epoch [4/5], Step [380/487], Loss: 0.2935, Precision=0.500, Recall=0.600\n","Epoch [4/5], Step [390/487], Loss: 0.2929, Precision=0.545, Recall=0.667\n","Epoch [4/5], Step [400/487], Loss: 0.2928, Precision=0.500, Recall=0.800\n","Epoch [4/5], Step [410/487], Loss: 0.2918, Precision=0.333, Recall=0.333\n","Epoch [4/5], Step [420/487], Loss: 0.2904, Precision=0.667, Recall=1.000\n","Epoch [4/5], Step [430/487], Loss: 0.2898, Precision=1.000, Recall=0.667\n","Epoch [4/5], Step [440/487], Loss: 0.2899, Precision=0.875, Recall=1.000\n","Epoch [4/5], Step [450/487], Loss: 0.2903, Precision=0.667, Recall=0.667\n","Epoch [4/5], Step [460/487], Loss: 0.2932, Precision=0.500, Recall=0.333\n","Epoch [4/5], Step [470/487], Loss: 0.2935, Precision=0.667, Recall=0.600\n","Epoch [4/5], Step [480/487], Loss: 0.2928, Precision=0.778, Recall=0.875\n","\n","Per-Class mAP:\n","  DHelmet: 0.501\n","  DNoHelmet: 0.336\n","  DHelmetP1Helmet: 0.381\n","  DNoHelmetP1NoHelmet: 0.175\n","Epoch [4/5] finished, Avg Loss: 0.2929, Avg Precision=0.568, Avg Recall=0.616, Validation mAP=0.348, Validation mAR=0.696\n","{'map': tensor(0.3481), 'map_50': tensor(0.4938), 'map_75': tensor(0.4492), 'map_small': tensor(-1.), 'map_medium': tensor(0.2250), 'map_large': tensor(0.3856), 'mar_1': tensor(0.4068), 'mar_10': tensor(0.6964), 'mar_100': tensor(0.6964), 'mar_small': tensor(-1.), 'mar_medium': tensor(0.5363), 'mar_large': tensor(0.7308), 'map_per_class': tensor([0.5008, 0.3357, 0.3806, 0.1750]), 'mar_100_per_class': tensor([0.7021, 0.6187, 0.7000, 0.7647]), 'classes': tensor([1, 2, 3, 4], dtype=torch.int32)}\n","Epoch [5/5], Step [10/487], Loss: 0.3619, Precision=0.833, Recall=0.714\n","Epoch [5/5], Step [20/487], Loss: 0.2792, Precision=1.000, Recall=0.750\n","Epoch [5/5], Step [30/487], Loss: 0.2643, Precision=0.667, Recall=0.667\n","Epoch [5/5], Step [40/487], Loss: 0.2513, Precision=0.500, Recall=0.600\n","Epoch [5/5], Step [50/487], Loss: 0.2469, Precision=0.667, Recall=0.571\n","Epoch [5/5], Step [60/487], Loss: 0.2422, Precision=0.714, Recall=0.714\n","Epoch [5/5], Step [70/487], Loss: 0.2435, Precision=0.000, Recall=0.000\n","Epoch [5/5], Step [80/487], Loss: 0.2504, Precision=0.800, Recall=0.571\n","Epoch [5/5], Step [90/487], Loss: 0.2513, Precision=0.556, Recall=0.625\n","Epoch [5/5], Step [100/487], Loss: 0.2636, Precision=0.417, Recall=0.455\n","Epoch [5/5], Step [110/487], Loss: 0.2659, Precision=0.000, Recall=0.000\n","Epoch [5/5], Step [120/487], Loss: 0.2627, Precision=0.333, Recall=0.333\n","Epoch [5/5], Step [130/487], Loss: 0.2657, Precision=0.500, Recall=0.500\n","Epoch [5/5], Step [140/487], Loss: 0.2685, Precision=0.667, Recall=0.667\n","Epoch [5/5], Step [150/487], Loss: 0.2686, Precision=0.800, Recall=1.000\n","Epoch [5/5], Step [160/487], Loss: 0.2683, Precision=0.625, Recall=1.000\n","Epoch [5/5], Step [170/487], Loss: 0.2686, Precision=0.600, Recall=0.857\n","Epoch [5/5], Step [180/487], Loss: 0.2719, Precision=0.667, Recall=0.615\n","Epoch [5/5], Step [190/487], Loss: 0.2719, Precision=0.429, Recall=0.600\n","Epoch [5/5], Step [200/487], Loss: 0.2734, Precision=0.714, Recall=0.769\n","Epoch [5/5], Step [210/487], Loss: 0.2724, Precision=1.000, Recall=1.000\n","Epoch [5/5], Step [220/487], Loss: 0.2730, Precision=0.667, Recall=0.667\n","Epoch [5/5], Step [230/487], Loss: 0.2754, Precision=1.000, Recall=0.500\n","Epoch [5/5], Step [240/487], Loss: 0.2795, Precision=0.500, Recall=0.571\n","Epoch [5/5], Step [250/487], Loss: 0.2792, Precision=0.500, Recall=0.556\n","Epoch [5/5], Step [260/487], Loss: 0.2800, Precision=0.643, Recall=0.900\n","Epoch [5/5], Step [270/487], Loss: 0.2800, Precision=0.333, Recall=0.500\n","Epoch [5/5], Step [280/487], Loss: 0.2808, Precision=0.667, Recall=0.667\n","Epoch [5/5], Step [290/487], Loss: 0.2781, Precision=0.750, Recall=1.000\n","Epoch [5/5], Step [300/487], Loss: 0.2771, Precision=0.250, Recall=0.500\n","Epoch [5/5], Step [310/487], Loss: 0.2750, Precision=0.750, Recall=0.857\n","Epoch [5/5], Step [320/487], Loss: 0.2737, Precision=0.556, Recall=1.000\n","Epoch [5/5], Step [330/487], Loss: 0.2740, Precision=0.444, Recall=0.444\n","Epoch [5/5], Step [340/487], Loss: 0.2744, Precision=0.455, Recall=0.455\n","Epoch [5/5], Step [350/487], Loss: 0.2728, Precision=0.500, Recall=0.333\n","Epoch [5/5], Step [360/487], Loss: 0.2717, Precision=0.500, Recall=0.500\n","Epoch [5/5], Step [370/487], Loss: 0.2704, Precision=0.875, Recall=0.875\n","Epoch [5/5], Step [380/487], Loss: 0.2703, Precision=0.500, Recall=0.667\n","Epoch [5/5], Step [390/487], Loss: 0.2689, Precision=1.000, Recall=0.500\n","Epoch [5/5], Step [400/487], Loss: 0.2702, Precision=0.250, Recall=0.222\n","Epoch [5/5], Step [410/487], Loss: 0.2714, Precision=0.778, Recall=0.636\n","Epoch [5/5], Step [420/487], Loss: 0.2718, Precision=0.625, Recall=0.714\n","Epoch [5/5], Step [430/487], Loss: 0.2698, Precision=0.833, Recall=0.833\n","Epoch [5/5], Step [440/487], Loss: 0.2699, Precision=1.000, Recall=1.000\n","Epoch [5/5], Step [450/487], Loss: 0.2710, Precision=0.714, Recall=0.556\n","Epoch [5/5], Step [460/487], Loss: 0.2718, Precision=0.800, Recall=0.667\n","Epoch [5/5], Step [470/487], Loss: 0.2729, Precision=0.533, Recall=1.000\n","Epoch [5/5], Step [480/487], Loss: 0.2731, Precision=0.667, Recall=0.800\n","\n","Per-Class mAP:\n","  DHelmet: 0.582\n","  DNoHelmet: 0.453\n","  DHelmetP1Helmet: 0.459\n","  DNoHelmetP1NoHelmet: 0.388\n","Epoch [5/5] finished, Avg Loss: 0.2738, Avg Precision=0.598, Avg Recall=0.672, Validation mAP=0.471, Validation mAR=0.738\n","{'map': tensor(0.4708), 'map_50': tensor(0.6066), 'map_75': tensor(0.5902), 'map_small': tensor(-1.), 'map_medium': tensor(0.2430), 'map_large': tensor(0.5185), 'mar_1': tensor(0.4675), 'mar_10': tensor(0.7376), 'mar_100': tensor(0.7376), 'mar_small': tensor(-1.), 'mar_medium': tensor(0.5962), 'mar_large': tensor(0.7665), 'map_per_class': tensor([0.5821, 0.4534, 0.4591, 0.3885]), 'mar_100_per_class': tensor([0.7636, 0.6854, 0.7279, 0.7735]), 'classes': tensor([1, 2, 3, 4], dtype=torch.int32)}\n","\n","Total training time: 0h 52m 14.5s\n"]}],"source":["import time\n","\n","# --- Training Loop with Evaluation ----\n","num_epochs = 5\n","start_time = time.time()\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    epoch_precisions, epoch_recalls = [], []\n","\n","    for i, (images, targets) in enumerate(train_dataloader):\n","        images = [img.to(device) for img in images]\n","        # Ensure each target is proper dict\n","        targets = [\n","            {\n","                \"boxes\": t[\"boxes\"].to(device).float(),\n","                \"labels\": t[\"labels\"].to(device).long(),\n","                \"image_id\": t[\"image_id\"].to(device).long(),\n","                \"area\": t[\"area\"].to(device).float(),\n","                \"iscrowd\": t[\"iscrowd\"].to(device).long(),\n","            }\n","            for t in targets\n","        ]\n","\n","        loss_dict = model(images, targets)\n","        losses = sum(loss for loss in loss_dict.values())\n","\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","\n","        running_loss += losses.item()\n","\n","        model.eval()\n","        with torch.no_grad():\n","            outputs = model(images)\n","            precision, recall = precision_recall_for_batch(outputs, targets)\n","            epoch_precisions.append(precision)\n","            epoch_recalls.append(recall)\n","        model.train()\n","\n","        if (i + 1) % 10 == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_dataloader)}], \"\n","                  f\"Loss: {running_loss / (i+1):.4f}, Precision={precision:.3f}, Recall={recall:.3f}\")\n","\n","    avg_loss = running_loss / len(train_dataloader)\n","    avg_precision = sum(epoch_precisions) / len(epoch_precisions)\n","    avg_recall = sum(epoch_recalls) / len(epoch_recalls)\n","\n","    # evaluate on validation set\n","    class_names = [\"DHelmet\", \"DNoHelmet\", \"DHelmetP1Helmet\", \"DNoHelmetP1NoHelmet\"]\n","    results = evaluate_model(model, val_dataloader, device, class_names=class_names)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}] finished, Avg Loss: {avg_loss:.4f}, Avg Precision={avg_precision:.3f}, Avg Recall={avg_recall:.3f}, Validation mAP={results['map']:.3f}, Validation mAR={results['mar_100']:.3f}\")\n","    print(results)\n","\n","# --- Total training time ---\n","end_time = time.time()\n","total_time = end_time - start_time\n","hours, rem = divmod(total_time, 3600)\n","minutes, seconds = divmod(rem, 60)\n","print(f\"\\nTotal training time: {int(hours)}h {int(minutes)}m {seconds:.1f}s\")"]},{"cell_type":"markdown","metadata":{"id":"9cbb0fa1"},"source":["### Evaluate the faster r-cnn model\n","\n","Evaluate the trained Faster R-CNN model on the custom test data.\n"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48606,"status":"ok","timestamp":1756888616885,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"},"user_tz":-480},"id":"addfe64f","outputId":"36be1df0-4d58-4ea5-fca5-7ade5c81d4b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Overall Metrics:\n","mAP@[.5:.95]: 0.420\n","mAP@0.5:     0.553\n","mAP@0.75:    0.525\n","mAR@100:     0.757\n","\n","=== Per-Class Metrics ===\n","              Class  mAP@[.5:.95]  mAR@100\n","            DHelmet         0.588    0.764\n","          DNoHelmet         0.493    0.761\n","    DHelmetP1Helmet         0.420    0.805\n","DNoHelmetP1NoHelmet         0.181    0.698\n","{'map': tensor(0.4205), 'map_50': tensor(0.5532), 'map_75': tensor(0.5245), 'map_small': tensor(-1.), 'map_medium': tensor(0.2219), 'map_large': tensor(0.4597), 'mar_1': tensor(0.3800), 'mar_10': tensor(0.7533), 'mar_100': tensor(0.7570), 'mar_small': tensor(-1.), 'mar_medium': tensor(0.7315), 'mar_large': tensor(0.7621), 'map_per_class': tensor([0.5880, 0.4934, 0.4196, 0.1807]), 'mar_100_per_class': tensor([0.7642, 0.7609, 0.8047, 0.6980]), 'classes': tensor([1, 2, 3, 4], dtype=torch.int32)}\n"]}],"source":["from torchmetrics.detection import MeanAveragePrecision\n","import pandas as pd\n","\n","def evaluate_model(model, test_dataloader, device, class_names=None):\n","    model.eval()\n","    metric = MeanAveragePrecision(class_metrics=True)\n","\n","    with torch.no_grad():\n","        for images, targets in test_dataloader:\n","            images = [img.to(device) for img in images]\n","            outputs = model(images)\n","\n","            # Move outputs & targets back to CPU for metric calculation\n","            outputs = [{k: v.cpu() for k, v in t.items()} for t in outputs]\n","            targets = [{k: v.cpu() for k, v in t.items()} for t in targets]\n","\n","            metric.update(outputs, targets)\n","\n","    results = metric.compute()\n","\n","     # Print overall metrics\n","    print(\"\\nOverall Metrics:\")\n","    print(f\"mAP@[.5:.95]: {results['map']:.3f}\")\n","    print(f\"mAP@0.5:     {results['map_50']:.3f}\")\n","    print(f\"mAP@0.75:    {results['map_75']:.3f}\")\n","    print(f\"mAR@100:     {results['mar_100']:.3f}\")\n","\n","    # Print per-class metrics\n","    if 'map_per_class' in results and results['map_per_class'] is not None:\n","        map_per_class = results['map_per_class'].cpu().numpy()\n","        mar_per_class = results['mar_100_per_class'].cpu().numpy()\n","        classes = results['classes'].cpu().numpy()\n","\n","        rows = []\n","        for i, cls_id in enumerate(classes):\n","            label = class_names[cls_id] if class_names and cls_id < len(class_names) else f\"Class {cls_id}\"\n","            rows.append([label,\n","                round(float(map_per_class[i]), 3),\n","                round(float(mar_per_class[i]), 3)])\n","\n","        df = pd.DataFrame(rows, columns=[\"Class\", \"mAP@[.5:.95]\", \"mAR@100\"])\n","        print(\"\\n=== Per-Class Metrics ===\")\n","        print(df.to_string(index=False))\n","\n","    return results\n","\n","class_names = [\"Background\", \"DHelmet\", \"DNoHelmet\", \"DHelmetP1Helmet\", \"DNoHelmetP1NoHelmet\"]\n","results = evaluate_model(model, test_dataloader, device, class_names=class_names)\n","print(results)\n"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":998},"id":"D58XDBOQka3k","executionInfo":{"status":"ok","timestamp":1756888658405,"user_tz":-480,"elapsed":41522,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"}},"outputId":"c9d8da67-4c9f-40c1-a1f8-a4a03a36862b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Overall Metrics for Test Data:\n","Precision: 0.5388\n","Recall:    0.4813\n","F1 Score:  0.4924\n","\n","Classification Report:\n","                     precision    recall  f1-score   support\n","\n","            DHelmet       0.67      0.51      0.58       487\n","          DNoHelmet       0.57      0.50      0.53       141\n","    DHelmetP1Helmet       0.24      0.53      0.33       158\n","DNoHelmetP1NoHelmet       0.00      0.00      0.00        45\n","\n","           accuracy                           0.48       831\n","          macro avg       0.37      0.38      0.36       831\n","       weighted avg       0.54      0.48      0.49       831\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 800x600 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import torch\n","from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# --- Evaluation ---\n","model.eval()\n","confidence_threshold = 0.4\n","all_true = []\n","all_pred = []\n","\n","with torch.no_grad():\n","    for images, targets in test_dataloader:\n","        images = [img.to(device) for img in images]\n","        outputs = model(images)\n","\n","        for i, output in enumerate(outputs):\n","            true_labels = targets[i][\"labels\"].cpu().numpy()\n","            scores = output[\"scores\"].cpu().numpy()\n","            labels = output[\"labels\"].cpu().numpy()\n","            mask = scores >= confidence_threshold\n","            pred_labels = labels[mask]\n","\n","            # Align lengths (truncate or pad)\n","            min_len = min(len(true_labels), len(pred_labels))\n","            if min_len > 0:\n","                all_true.extend(true_labels[:min_len])\n","                all_pred.extend(pred_labels[:min_len])\n","\n","\n","# --- Metrics ---\n","precision = precision_score(all_true, all_pred, average=\"weighted\", zero_division=0)\n","recall = recall_score(all_true, all_pred, average=\"weighted\", zero_division=0)\n","f1 = f1_score(all_true, all_pred, average=\"weighted\", zero_division=0)\n","\n","print(\"\\nOverall Metrics for Test Data:\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall:    {recall:.4f}\")\n","print(f\"F1 Score:  {f1:.4f}\")\n","\n","label_names = [\"DHelmet\",\"DNoHelmet\",\"DHelmetP1Helmet\",\"DNoHelmetP1NoHelmet\"]\n","# Detailed per-class report\n","print(\"\\nClassification Report:\")\n","print(classification_report(all_true, all_pred, target_names=list(train_dataset.class_to_label.keys())))\n","\n","# --- Confusion Matrix ---\n","cm = confusion_matrix(all_true, all_pred, labels=[1,2,3,4])\n","plt.figure(figsize=(8,6))\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n","            xticklabels=label_names,\n","            yticklabels=label_names)\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"3bdd1736"},"source":["### Save the trained model\n","\n","Save the state dictionary of the trained Faster R-CNN model to a file.\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":282,"status":"ok","timestamp":1756887852642,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"},"user_tz":-480},"id":"8ff39813","outputId":"806a7dcd-4310-4bb2-9cf0-fac99977c632"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model state dictionary saved successfully to faster_rcnn_model.pth\n"]}],"source":["# 1. Define the path where the model state dictionary will be saved.\n","model_save_path = 'faster_rcnn_model.pth'\n","\n","# 2. Save the model's state dictionary using torch.save().\n","torch.save(model.state_dict(), model_save_path)\n","\n","# 3. Print a confirmation message indicating that the model has been saved successfully.\n","print(f\"Model state dictionary saved successfully to {model_save_path}\")"]},{"cell_type":"markdown","metadata":{"id":"5acf6a60"},"source":["## Detect Object and Perform Counting\n"]},{"cell_type":"markdown","metadata":{"id":"IHHkdKaVka3l"},"source":["### Load the saved model\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ODlcTEcka3l","executionInfo":{"status":"ok","timestamp":1756888510875,"user_tz":-480,"elapsed":6,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"}},"outputId":"c0c72b95-d9e5-41e5-c035-f9ca5d89498d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tesla T4\n","Using device: cuda\n"]}],"source":["import cv2\n","import torch\n","print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU only\")\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12568,"status":"ok","timestamp":1756888551170,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"},"user_tz":-480},"id":"05b56fde","outputId":"fa9cab02-dfae-4fd2-a728-ca00a9337272"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97.8M/97.8M [00:00<00:00, 146MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Model loaded successfully from /content/drive/MyDrive/DegreeY3S1/BMDS2133_ImageProcessing/Assignment/FasterRCNN/faster_rcnn_model.pth and moved to cuda.\n"]}],"source":["from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","\n","# class names\n","label_list= [\"\",\"DHelmet\", \"DNoHelmet\", \"DHelmetP1Helmet\", \"DNoHelmetP1NoHelmet\"]\n","\n","# 1. Define the number of classes for the model's head.\n","# Background + 4 custom classes\n","num_classes = 5\n","\n","# 2. Instantiate the Faster R-CNN model with a ResNet50-FPN backbone.\n","# Make sure not to load the default pre-trained weights at this stage.\n","# Use weights=None to avoid loading default weights\n","model = fasterrcnn_resnet50_fpn(weights=None, num_classes=num_classes)\n","\n","# 3. Define the path from where the model state dictionary will be loaded.\n","model_load_path = '/content/drive/MyDrive/DegreeY3S1/BMDS2133_ImageProcessing/Assignment/FasterRCNN/faster_rcnn_model.pth'\n","\n","# 4. Load the saved state dictionary into the modified model.\n","model.load_state_dict(torch.load(model_load_path))\n","\n","# 5. Move the loaded model to the appropriate device (CPU or GPU).\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)\n","\n","# 6. Print a confirmation message.\n","print(f\"Model loaded successfully from {model_load_path} and moved to {device}.\")"]},{"cell_type":"markdown","metadata":{"id":"e0775834"},"source":["### Evaluate the model to detect objects in different scenario\n"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1IPFmf_oYxjlzn-4WOBBtQbRC-j3M6oxJ"},"executionInfo":{"elapsed":2614,"status":"ok","timestamp":1756890134388,"user":{"displayName":"SHIR CHENG NG","userId":"17724487929570021560"},"user_tz":-480},"id":"baea3d7d","outputId":"12ea5529-da05-4a75-aa56-f74f730a64a0"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import os\n","import torch\n","from PIL import Image\n","from torchvision.transforms import functional as F\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# 1. Define the path to the test image\n","test_folder = '/content/drive/MyDrive/DegreeY3S1/BMDS2133_ImageProcessing/Assignment/dataset/augmented_samples'\n","annotation_file = \"/content/drive/MyDrive/DegreeY3S1/BMDS2133_ImageProcessing/Assignment/dataset/preprocessed_data/fasterrcnn_annotations/fasterrcnn_test.json\"\n","\n","# Label map\n","label_to_class = {\n","    1: 'DHelmet',\n","    2: 'DNoHelmet',\n","    3: 'DHelmetP1Helmet',\n","    4: 'DNoHelmetP1NoHelmet'\n","}\n","\n","# Load annotation JSON\n","with open(annotation_file, \"r\") as f:\n","    test_annotations = json.load(f)\n","\n","confidence_threshold = 0.4\n","\n","for file_name in os.listdir(test_folder):\n","    if not file_name.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n","        continue\n","\n","    # Ground truth\n","    file_path = \"/kaggle/input/helmet-dataset-by-osf-lite/helmet-dataset/images/part_2/Mandalay_1_128/20.jpg\"\n","    if file_path not in test_annotations:\n","        print(f\"No ground truth for {file_path}, skipping.\")\n","        continue\n","\n","    gt_info = test_annotations[file_path]\n","    gt_boxes = torch.tensor([obj[\"bbox\"] for obj in gt_info], dtype=torch.float32)\n","    gt_labels = torch.tensor([obj[\"label\"] for obj in gt_info], dtype=torch.int64)\n","\n","    # Load image\n","    test_file_path = os.path.join(test_folder, file_name)\n","    image_pil = Image.open(test_file_path).convert(\"RGB\")\n","    image_tensor = F.to_tensor(image_pil).unsqueeze(0).to(device)\n","\n","    # Inference\n","    model.eval()\n","    with torch.no_grad():\n","        output = model(image_tensor)[0]\n","\n","    mask = output[\"scores\"] >= confidence_threshold\n","    pred_boxes = output[\"boxes\"][mask].cpu()\n","    pred_labels = output[\"labels\"][mask].cpu()\n","    pred_scores = output[\"scores\"][mask].cpu()\n","\n","    # Metrics\n","    all_true, all_pred = [], []\n","    min_len = min(len(gt_labels), len(pred_labels))\n","    if min_len > 0:\n","        all_true = gt_labels[:min_len].numpy()\n","        all_pred = pred_labels[:min_len].numpy()\n","\n","        precision = precision_score(all_true, all_pred, average=\"weighted\", zero_division=0)\n","        recall = recall_score(all_true, all_pred, average=\"weighted\", zero_division=0)\n","        f1 = f1_score(all_true, all_pred, average=\"weighted\", zero_division=0)\n","    else:\n","        precision = recall = f1 = 0.0\n","\n","    # Print detections metrics\n","    print(f\"\\n{file_name} results:\")\n","    print(f\"Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}\")\n","    for box, label, score in zip(pred_boxes, pred_labels, pred_scores):\n","        print(f\" Det: {label_to_class.get(label.item(),'?')} \"\n","              f\"({score:.4f}), Box={box.tolist()}\")\n","\n","    # Helmet count\n","    helmet_wearers, no_helmet_wearers = 0, 0\n","    for label in pred_labels:\n","        if label.item() == 1:  # DHelmet\n","            helmet_wearers += 1\n","        elif label.item() == 2:  # DNoHelmet\n","            no_helmet_wearers += 1\n","        elif label.item() == 3:  # DHelmetP1Helmet\n","            helmet_wearers += 2\n","        elif label.item() == 4:  # DNoHelmetP1NoHelmet\n","            no_helmet_wearers += 2\n","\n","    # Draw detections\n","    image_np = np.array(image_pil)\n","    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n","    text_color = (255, 255, 255)  # white text\n","    font = cv2.FONT_HERSHEY_SIMPLEX\n","    font_scale = 0.5\n","    thickness = 2\n","\n","    if len(pred_boxes) > 0:\n","        for box, label, score in zip(pred_boxes, pred_labels, pred_scores):\n","            x_min, y_min, x_max, y_max = [int(coord) for coord in box.tolist()]\n","\n","            # Choose color: green for helmet, red for no helmet\n","            if label.item() in [2, 4]:\n","                box_color = (0, 0, 255)   # Red\n","            elif label.item() in [1, 3]:\n","                box_color = (0, 255, 0)   # Green\n","            else:\n","                box_color = (255, 255, 255)\n","\n","            # Draw box\n","            cv2.rectangle(image_bgr, (x_min, y_min), (x_max, y_max), box_color, thickness)\n","\n","            # Label + confidence\n","            class_name = label_to_class.get(label.item(), f\"Unknown-{label.item()}\")\n","            display_text = f\"{class_name}: {score.item():.2f}\"\n","\n","            # Put text above the box\n","            text_size, _ = cv2.getTextSize(display_text, font, font_scale, thickness)\n","            text_x = x_min\n","            text_y = y_min - 10\n","            if text_y < text_size[1]:\n","                text_y = y_min + text_size[1]\n","            cv2.putText(image_bgr, display_text, (text_x, text_y),\n","                        font, font_scale, text_color, thickness)\n","    else:\n","        print(\"No detections found above threshold.\")\n","\n","    # Convert back to RGB for matplotlib\n","    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n","\n","    # ===================== DISPLAY =====================\n","    plt.figure(figsize=(12, 8))\n","    plt.imshow(image_rgb)\n","    plt.axis(\"off\")\n","    plt.title(f\"{file_name}\\n\"\n","            f\"Precision={precision:.4f}, Recall={recall:.4f}, F1-score={f1:.4f}\\n\"\n","            f\"Helmet={helmet_wearers}, NoHelmet={no_helmet_wearers}\")\n","    plt.show()"]},{"cell_type":"code","source":[],"metadata":{"id":"oZ9nSJUXuGwt"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.5"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}